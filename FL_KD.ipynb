{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sunidhi-Gautam/FL_Implementation/blob/main/FL_KD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCs4i_erSmMt",
        "outputId": "070cf604-09c5-4e4d-dbfa-d4f8010a747b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "0xPQiG1lSxxi",
        "outputId": "71878637-81f6-4d88-b4af-1c9e27216b55"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-92b972c2-cbfa-4916-9e47-de94b51095d1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-92b972c2-cbfa-4916-9e47-de94b51095d1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"sunidhigautam26\",\"key\":\"df9c2dd0e0f5995bb0a2fd692c71ec16\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "oAQRVA9iSzRV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports for the Dataset Download**"
      ],
      "metadata": {
        "id": "XZLbt2f7S08L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import zipfile\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "U2dhWArxS41w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAW_DATASETS_DIR = \"/content/raw_teacher_datasets\"\n",
        "os.makedirs(RAW_DATASETS_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Raw datasets will be stored in:\", RAW_DATASETS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wac5uYAEM7CA",
        "outputId": "15ff2f7e-e1c7-497c-d269-6d858bfeb857"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw datasets will be stored in: /content/raw_teacher_datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset 1: Tomato Village**"
      ],
      "metadata": {
        "id": "ygDDt_uUS7Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading Dataset 1: Tomato Village (GitHub)\")\n",
        "\n",
        "!git clone https://github.com/mamta-joshi-gehlot/Tomato-Village.git /content/tmp_tomato_village\n",
        "\n",
        "shutil.move(\n",
        "    \"/content/tmp_tomato_village\",\n",
        "    os.path.join(RAW_DATASETS_DIR, \"dataset_1_tomato_village\")\n",
        ")\n",
        "\n",
        "print(\"Dataset 1 ready\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u36l3DHRS6rd",
        "outputId": "3ebc2287-07dd-4411-dfbf-66bbee39bd4a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Dataset 1: Tomato Village (GitHub)\n",
            "Cloning into '/content/tmp_tomato_village'...\n",
            "remote: Enumerating objects: 45041, done.\u001b[K\n",
            "remote: Counting objects: 100% (26934/26934), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15220/15220), done.\u001b[K\n",
            "remote: Total 45041 (delta 11469), reused 26919 (delta 11462), pack-reused 18107 (from 1)\u001b[K\n",
            "Receiving objects: 100% (45041/45041), 3.15 GiB | 16.29 MiB/s, done.\n",
            "Resolving deltas: 100% (14334/14334), done.\n",
            "Updating files: 100% (53289/53289), done.\n",
            "Dataset 1 ready\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset 2: Kaggle 1 (Tomato Leaf)**"
      ],
      "metadata": {
        "id": "-jEE_miuNo61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading Dataset 2: Tomato Leaf (Kaggle)\")\n",
        "\n",
        "!kaggle datasets download -d kaustubhb999/tomatoleaf -p /content\n",
        "\n",
        "zip_path = \"/content/tomatoleaf.zip\"\n",
        "extract_path = \"/content/tmp_tomatoleaf\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(extract_path)\n",
        "\n",
        "shutil.move(\n",
        "    extract_path,\n",
        "    os.path.join(RAW_DATASETS_DIR, \"dataset_2_tomatoleaf\")\n",
        ")\n",
        "\n",
        "print(\"Dataset 2 ready\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIV0NGgqNm_3",
        "outputId": "a6172e85-4ea7-485b-aaf4-dde20b4f4eda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Dataset 2: Tomato Leaf (Kaggle)\n",
            "Dataset URL: https://www.kaggle.com/datasets/kaustubhb999/tomatoleaf\n",
            "License(s): CC0-1.0\n",
            "Downloading tomatoleaf.zip to /content\n",
            " 86% 153M/179M [00:00<00:00, 1.60GB/s]\n",
            "100% 179M/179M [00:00<00:00, 1.25GB/s]\n",
            "Dataset 2 ready\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset 3: Kaggle 2 (Tomato – Ashish Motwani)**"
      ],
      "metadata": {
        "id": "l1CQSOgoNwsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading Dataset 3: Tomato (Kaggle - Ashish Motwani)\")\n",
        "\n",
        "!kaggle datasets download -d ashishmotwani/tomato -p /content\n",
        "\n",
        "zip_path = \"/content/tomato.zip\"\n",
        "extract_path = \"/content/tmp_tomato_3\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(extract_path)\n",
        "\n",
        "shutil.move(\n",
        "    extract_path,\n",
        "    os.path.join(RAW_DATASETS_DIR, \"dataset_3_tomato\")\n",
        ")\n",
        "\n",
        "print(\"Dataset 3 ready\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zQx-gFrN3Tj",
        "outputId": "f413b6d2-3463-4a02-9a01-66c69386dea4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Dataset 3: Tomato (Kaggle - Ashish Motwani)\n",
            "Dataset URL: https://www.kaggle.com/datasets/ashishmotwani/tomato\n",
            "License(s): copyright-authors\n",
            "Downloading tomato.zip to /content\n",
            " 99% 1.36G/1.37G [00:05<00:00, 256MB/s]\n",
            "100% 1.37G/1.37G [00:05<00:00, 280MB/s]\n",
            "Dataset 3 ready\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset 4: Kaggle 3 (Tomato Disease)**"
      ],
      "metadata": {
        "id": "vB1kwgi1N4j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading Dataset 4: Tomato Diseases (Kaggle)\")\n",
        "\n",
        "!kaggle datasets download -d luisolazo/tomato-diseases -p /content\n",
        "\n",
        "zip_path = \"/content/tomato-diseases.zip\"\n",
        "extract_path = \"/content/tmp_tomato_diseases\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(extract_path)\n",
        "\n",
        "shutil.move(\n",
        "    extract_path,\n",
        "    os.path.join(RAW_DATASETS_DIR, \"dataset_4_tomato_diseases\")\n",
        ")\n",
        "\n",
        "print(\"Dataset 4 ready\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YstSPA7DNjO8",
        "outputId": "bc40b830-8477-460e-c77d-beaf9b417e3e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Dataset 4: Tomato Diseases (Kaggle)\n",
            "Dataset URL: https://www.kaggle.com/datasets/luisolazo/tomato-diseases\n",
            "License(s): CC0-1.0\n",
            "Downloading tomato-diseases.zip to /content\n",
            " 94% 386M/411M [00:01<00:00, 301MB/s]\n",
            "100% 411M/411M [00:01<00:00, 376MB/s]\n",
            "Dataset 4 ready\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Verify Downloads**"
      ],
      "metadata": {
        "id": "GNWqnNDBOCRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFinal raw datasets available:\\n\")\n",
        "\n",
        "for d in sorted(os.listdir(RAW_DATASETS_DIR)):\n",
        "    print(\"•\", d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd13u60TOBL4",
        "outputId": "618c5871-2c35-432d-d84c-ebea5719e535"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final raw datasets available:\n",
            "\n",
            "• dataset_1_tomato_village\n",
            "• dataset_2_tomatoleaf\n",
            "• dataset_3_tomato\n",
            "• dataset_4_tomato_diseases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Canonical Class Map**"
      ],
      "metadata": {
        "id": "pd522KwHOgq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_MAP = {\n",
        "    # Early blight\n",
        "    \"early_blight\": \"early_blight\",\n",
        "    \"Early_blight\": \"early_blight\",\n",
        "    \"Early Blight\": \"early_blight\",\n",
        "    \"tomato___early_blight\": \"early_blight\",\n",
        "    \"tomato__early blight\": \"early_blight\",\n",
        "    \"EARLY-BLIGHT\": \"early_blight\",\n",
        "\n",
        "\n",
        "    # Late blight\n",
        "    \"late_blight\": \"late_blight\",\n",
        "    \"Late_blight\": \"late_blight\",\n",
        "    \"Late Blight\": \"late_blight\",\n",
        "    \"tomato___late_blight\": \"late_blight\",\n",
        "    \"tomato__late blight\": \"late_blight\",\n",
        "\n",
        "\n",
        "    # Bacterial spot\n",
        "    \"bacterial_spot\": \"bacterial_spot\",\n",
        "    \"Bacterial Spot\": \"bacterial_spot\",\n",
        "    \"Tomato___Bacterial_spot\": \"bacterial_spot\",\n",
        "    \"Tomato_bacterial_spot\": \"bacterial_spot\",\n",
        "\n",
        "\n",
        "    # Leaf mold\n",
        "    \"leaf_mold\": \"leaf_mold\",\n",
        "    \"Leaf Mold\": \"leaf_mold\",\n",
        "    \"Leaf_Mold\": \"leaf_mold\",\n",
        "    \"tomato___Leaf_Mold\": \"leaf_mold\",\n",
        "\n",
        "\n",
        "    # Healthy\n",
        "    \"healthy\": \"healthy\",\n",
        "    \"Healthy\": \"healthy\",\n",
        "    \"Tomato___healthy\": \"healthy\",\n",
        "\n",
        "\n",
        "    # Target spot\n",
        "    \"target_spot\": \"target_spot\",\n",
        "    \"Target Spot\": \"target_spot\",\n",
        "    \"Target_Spot\": \"target_spot\",\n",
        "    \"target_spot___\": \"target_spot\",\n",
        "    \"tomato___Target_Spot\": \"target_spot\",\n",
        "\n",
        "\n",
        "    # Powdery Mildew\n",
        "    \"powdery_mildew\": \"powdery_mildew\",\n",
        "    \"Powdery Mildew\": \"powdery_mildew\",\n",
        "    \"Powdery_mildew\": \"powdery_mildew\",\n",
        "    \"Powdery_Mildew\": \"powdery_mildew\",\n",
        "\n",
        "\n",
        "    # Septoria Leaf Spot\n",
        "    \"septoria_leaf_spot\": \"septoria_leaf_spot\",\n",
        "    \"Septoria Leaf Spot\": \"septoria_leaf_spot\",\n",
        "    \"Septorialeafspot\": \"septoria_leaf_spot\",\n",
        "    \"tomato___Septoria_leaf_spot\": \"septoria_leaf_spot\",\n",
        "\n",
        "\n",
        "    # Mosaic virus\n",
        "    \"mosaic_virus\": \"mosaic_virus\",\n",
        "    \"Tomato_mosaic_virus\": \"mosaic_virus\",\n",
        "    \"tomato_mosaic_virus\": \"mosaic_virus\",\n",
        "    \"Tomato mosaic virus\": \"mosaic_virus\",\n",
        "    \"tomato___Tomato_mosaic_virus\": \"mosaic_virus\",\n",
        "\n",
        "\n",
        "    # Spider mites (Two-spotted)\n",
        "    \"spider_mites_two_spotted_spider_mite\": \"spider_mites\",\n",
        "    \"Spider Mites Two-spotted spider_mite\": \"spider_mites\",\n",
        "    \"Spider_mites\": \"spider_mites\",\n",
        "    \"spider_mites\": \"spider_mites\",\n",
        "    \"twospotted_spider_mite\": \"spider_mites\",\n",
        "    \"Tomato___Spider_mites Two-spotted_spider_mite\": \"spider_mites\",\n",
        "\n",
        "\n",
        "    # Yellow Leaf Curl Virus\n",
        "    \"yellow_leaf_curl_virus\": \"yellow_leaf_curl_virus\",\n",
        "    \"TomatoYellowLeafCurlVirus\": \"yellow_leaf_curl_virus\",\n",
        "    \"Tomato_Yellow_Leaf_Curl_Virus\": \"yellow_leaf_curl_virus\",\n",
        "    \"Yellow Leaf Curl Virus\": \"yellow_leaf_curl_virus\",\n",
        "    \"tomato___Tomato_Yellow_Leaf_Curl_Virus\": \"yellow_leaf_curl_virus\",\n",
        "\n",
        "\n",
        "    # Leaf Miner\n",
        "    \"leaf_miner\": \"leaf_miner\",\n",
        "    \"Leaf Miner\": \"leaf_miner\",\n",
        "    \"leaf miner\": \"leaf_miner\",\n",
        "\n",
        "\n",
        "    # Nitrogen deficiency\n",
        "    \"nitrogen_deficiency\": \"nitrogen_deficiency\",\n",
        "    \"Nitrogen Deficiency\": \"nitrogen_deficiency\",\n",
        "\n",
        "\n",
        "    # Potassium deficiency\n",
        "    \"potassium_deficiency\": \"potassium_deficiency\",\n",
        "    \"Pottassium Deficiency\": \"potassium_deficiency\",\n",
        "    \"Potassium Deficiency\": \"potassium_deficiency\",\n",
        "\n",
        "\n",
        "    # Magnesium deficiency\n",
        "    \"magnesium_deficiency\": \"magnesium_deficiency\",\n",
        "    \"Magnesium Deficiency\": \"magnesium_deficiency\",\n",
        "\n",
        "\n",
        "    # Spotted Wilt Virus\n",
        "    \"spotted_wilt_virus\": \"spotted_wilt_virus\",\n",
        "    \"Spotted Wilt Virus\": \"spotted_wilt_virus\",\n",
        "    \"Spotted_Wilt_Virus\": \"spotted_wilt_virus\",\n",
        "    \"Spotted wilt virus\": \"spotted_wilt_virus\",\n",
        "}"
      ],
      "metadata": {
        "id": "dnjcupZfOYX6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RAW_DATASETS_DIR = \"/content/raw_teacher_datasets\"\n",
        "TEACHER_DATASET_DIR = \"/content/teacher_dataset\"\n",
        "\n",
        "os.makedirs(TEACHER_DATASET_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "9_QuXcMtOlgo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IGNORE_FOLDERS = {\n",
        "    \"train\", \"val\", \"test\",\n",
        "    \"images\", \"image\", \"imgs\"\n",
        "}"
      ],
      "metadata": {
        "id": "HHm4SR4WSF5c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalize Class Names**"
      ],
      "metadata": {
        "id": "oVbcQ9x3On8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_class_name(raw):\n",
        "    raw = raw.strip().lower()\n",
        "\n",
        "    # Ignore structural folders\n",
        "    if raw in IGNORE_FOLDERS:\n",
        "        return None\n",
        "\n",
        "    # Remove PlantVillage prefix\n",
        "    if raw.startswith(\"tomato___\"):\n",
        "        raw = raw.replace(\"tomato___\", \"\")\n",
        "\n",
        "    # Cleanup\n",
        "    raw = raw.replace(\"-\", \"_\")\n",
        "    raw = raw.replace(\" \", \"_\")\n",
        "    raw = raw.replace(\"__\", \"_\")\n",
        "\n",
        "    # ---- Canonical merges ----\n",
        "\n",
        "    if \"spider\" in raw or \"mite\" in raw:\n",
        "        return \"spider_mites\"\n",
        "\n",
        "    if \"yellow\" in raw and \"curl\" in raw:\n",
        "        return \"yellow_leaf_curl_virus\"\n",
        "\n",
        "    if \"mosaic\" in raw:\n",
        "        return \"mosaic_virus\"\n",
        "\n",
        "    if \"septoria\" in raw:\n",
        "        return \"septoria_leaf_spot\"\n",
        "\n",
        "    if \"early\" in raw and \"blight\" in raw:\n",
        "        return \"early_blight\"\n",
        "\n",
        "    if \"late\" in raw and \"blight\" in raw:\n",
        "        return \"late_blight\"\n",
        "\n",
        "    if \"target\" in raw:\n",
        "        return \"target_spot\"\n",
        "\n",
        "    if \"leaf\" in raw and \"mold\" in raw:\n",
        "        return \"leaf_mold\"\n",
        "\n",
        "    # Nutrient deficiencies\n",
        "    if \"nitrogen\" in raw:\n",
        "        return \"nitrogen_deficiency\"\n",
        "\n",
        "    if \"pottassium\" in raw or \"potassium\" in raw:\n",
        "        return \"potassium_deficiency\"\n",
        "\n",
        "    if \"magnesium\" in raw:\n",
        "        return \"magnesium_deficiency\"\n",
        "\n",
        "    # Healthy\n",
        "    if raw == \"healthy\":\n",
        "        return \"healthy\"\n",
        "\n",
        "    return raw"
      ],
      "metadata": {
        "id": "UoBKiWIDOnRE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "\n",
        "TEACHER_DATASET_DIR = \"/content/teacher_dataset\"\n",
        "\n",
        "if os.path.exists(TEACHER_DATASET_DIR):\n",
        "    shutil.rmtree(TEACHER_DATASET_DIR)\n",
        "\n",
        "os.makedirs(TEACHER_DATASET_DIR)"
      ],
      "metadata": {
        "id": "HO04qK7gSNS4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge & Normalizing All Datasets**"
      ],
      "metadata": {
        "id": "_9_arqxpOw0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\")\n",
        "\n",
        "class_counter = {}\n",
        "total_images = 0\n",
        "\n",
        "for dataset in sorted(os.listdir(RAW_DATASETS_DIR)):\n",
        "    dataset_path = os.path.join(RAW_DATASETS_DIR, dataset)\n",
        "    print(f\"\\nProcessing {dataset}\")\n",
        "\n",
        "    for root, _, files in os.walk(dataset_path):\n",
        "        imgs = [f for f in files if f.lower().endswith(IMG_EXTS)]\n",
        "        if not imgs:\n",
        "            continue\n",
        "\n",
        "        raw_class = os.path.basename(root)\n",
        "        norm_class = normalize_class_name(raw_class)\n",
        "\n",
        "        if norm_class is None:\n",
        "            continue\n",
        "\n",
        "        dest_cls_dir = os.path.join(TEACHER_DATASET_DIR, norm_class)\n",
        "        os.makedirs(dest_cls_dir, exist_ok=True)\n",
        "\n",
        "        for img in imgs:\n",
        "            src = os.path.join(root, img)\n",
        "            dst = os.path.join(dest_cls_dir, f\"{dataset}_{img}\")\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "            class_counter[norm_class] = class_counter.get(norm_class, 0) + 1\n",
        "            total_images += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4k6O4wUOvOW",
        "outputId": "d3f7f4b9-ebf1-4d72-8573-46dfed9971b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing dataset_1_tomato_village\n",
            "\n",
            "Processing dataset_2_tomatoleaf\n",
            "\n",
            "Processing dataset_3_tomato\n",
            "\n",
            "Processing dataset_4_tomato_diseases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Teacher Dataset Summary**"
      ],
      "metadata": {
        "id": "vlnmWab-O3Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== CLEAN TEACHER DATASET SUMMARY =====\")\n",
        "print(f\"Total images: {total_images}\")\n",
        "print(f\"Total classes: {len(class_counter)}\\n\")\n",
        "\n",
        "for cls, cnt in sorted(class_counter.items()):\n",
        "    print(f\"{cls:<30} {cnt}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwUlVD1jO2fC",
        "outputId": "890f6ab9-dba6-4186-cbcb-8d5f3d82c484"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== CLEAN TEACHER DATASET SUMMARY =====\n",
            "Total images: 70252\n",
            "Total classes: 16\n",
            "\n",
            "bacterial_spot                 6781\n",
            "early_blight                   7315\n",
            "healthy                        7499\n",
            "late_blight                    8446\n",
            "leaf_miner                     1024\n",
            "leaf_mold                      6497\n",
            "magnesium_deficiency           936\n",
            "mosaic_virus                   5478\n",
            "nitrogen_deficiency            360\n",
            "potassium_deficiency           72\n",
            "powdery_mildew                 1256\n",
            "septoria_leaf_spot             6499\n",
            "spider_mites                   4958\n",
            "spotted_wilt_virus             517\n",
            "target_spot                    4938\n",
            "yellow_leaf_curl_virus         7676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Class Imbalance**"
      ],
      "metadata": {
        "id": "JSFCSODhTNht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class Frequencies**"
      ],
      "metadata": {
        "id": "4XgPj8UMTT3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "TEACHER_DATASET_DIR = \"/content/teacher_dataset\"\n",
        "\n",
        "class_counts = Counter()\n",
        "\n",
        "for cls in os.listdir(TEACHER_DATASET_DIR):\n",
        "    cls_path = os.path.join(TEACHER_DATASET_DIR, cls)\n",
        "    if not os.path.isdir(cls_path):\n",
        "        continue\n",
        "    class_counts[cls] = len(os.listdir(cls_path))\n",
        "\n",
        "print(\"\\n===== CLASS FREQUENCIES =====\")\n",
        "for c, n in sorted(class_counts.items()):\n",
        "    print(f\"{c:<30} {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww4WTR7qRubq",
        "outputId": "4d0a6c80-d33e-4640-ed25-ff9f53a07856"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== CLASS FREQUENCIES =====\n",
            "bacterial_spot                 6337\n",
            "early_blight                   6871\n",
            "healthy                        7055\n",
            "late_blight                    8002\n",
            "leaf_miner                     1024\n",
            "leaf_mold                      6053\n",
            "magnesium_deficiency           936\n",
            "mosaic_virus                   5034\n",
            "nitrogen_deficiency            360\n",
            "potassium_deficiency           72\n",
            "powdery_mildew                 1256\n",
            "septoria_leaf_spot             6055\n",
            "spider_mites                   4514\n",
            "spotted_wilt_virus             517\n",
            "target_spot                    4494\n",
            "yellow_leaf_curl_virus         7232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computing Class-Balanced Weights (CB-Loss)**\n",
        "\n",
        "$$\n",
        "w_c = \\frac{1 - \\beta}{1 - \\beta^{n_c}}\n",
        "$$\n",
        "\n",
        "n_c = no. of samples in class c\n",
        "\n",
        "β ϵ [0.9, 0.9999]\n",
        "\n",
        "Larger β --> stronger balancing"
      ],
      "metadata": {
        "id": "5pDnG0jbTbvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "beta = 0.999\n",
        "\n",
        "classes = sorted(class_counts.keys())\n",
        "class_to_idx = {c: i for i, c in enumerate(classes)}\n",
        "\n",
        "effective_num = {}\n",
        "weights = []\n",
        "\n",
        "for c in classes:\n",
        "    n = class_counts[c]\n",
        "    eff_n = 1.0 - np.power(beta, n)\n",
        "    w = (1.0 - beta) / eff_n\n",
        "    weights.append(w)\n",
        "    effective_num[c] = eff_n\n",
        "\n",
        "# Normalize weights\n",
        "weights = np.array(weights)\n",
        "weights = weights / weights.sum() * len(weights)\n",
        "\n",
        "class_weights = torch.tensor(weights, dtype=torch.float)\n",
        "\n",
        "print(\"\\n===== CLASS WEIGHTS =====\")\n",
        "for c, w in zip(classes, class_weights):\n",
        "    print(f\"{c:<30} {w:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kiorq9pvTZFa",
        "outputId": "09885418-2e51-46d2-daa1-54eb6a5202ef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== CLASS WEIGHTS =====\n",
            "bacterial_spot                 0.4604\n",
            "early_blight                   0.4601\n",
            "healthy                        0.4600\n",
            "late_blight                    0.4598\n",
            "leaf_miner                     0.7170\n",
            "leaf_mold                      0.4607\n",
            "magnesium_deficiency           0.7560\n",
            "mosaic_virus                   0.4626\n",
            "nitrogen_deficiency            1.5197\n",
            "potassium_deficiency           6.6130\n",
            "powdery_mildew                 0.6425\n",
            "septoria_leaf_spot             0.4607\n",
            "spider_mites                   0.4647\n",
            "spotted_wilt_virus             1.1381\n",
            "target_spot                    0.4648\n",
            "yellow_leaf_curl_virus         0.4600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Teacher Dataset**"
      ],
      "metadata": {
        "id": "stHBB0keU7GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "ArAWQbHBUrGj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEACHER_DATASET = \"/content/teacher_dataset\"  # root folder\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "mWMe4to6U_4y"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "tdLOko3NVAWW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_dataset = datasets.ImageFolder(\n",
        "    root=TEACHER_DATASET,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(\"Total samples:\", len(teacher_dataset))\n",
        "print(\"Classes:\", teacher_dataset.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leYn95szVB4D",
        "outputId": "e6899e80-fe9a-484e-eb8c-07e41c1d32fe"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 65812\n",
            "Classes: ['bacterial_spot', 'early_blight', 'healthy', 'late_blight', 'leaf_miner', 'leaf_mold', 'magnesium_deficiency', 'mosaic_virus', 'nitrogen_deficiency', 'potassium_deficiency', 'powdery_mildew', 'septoria_leaf_spot', 'spider_mites', 'spotted_wilt_virus', 'target_spot', 'yellow_leaf_curl_virus']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dict(enumerate(teacher_dataset.classes)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpgUtnQ6VPEk",
        "outputId": "25d2148e-e208-4c8c-9660-5c377957f208"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'bacterial_spot', 1: 'early_blight', 2: 'healthy', 3: 'late_blight', 4: 'leaf_miner', 5: 'leaf_mold', 6: 'magnesium_deficiency', 7: 'mosaic_virus', 8: 'nitrogen_deficiency', 9: 'potassium_deficiency', 10: 'powdery_mildew', 11: 'septoria_leaf_spot', 12: 'spider_mites', 13: 'spotted_wilt_virus', 14: 'target_spot', 15: 'yellow_leaf_curl_virus'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Injecting Class Weights**"
      ],
      "metadata": {
        "id": "zFX8QCMjVFf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Order MUST match teacher_dataset.classes\n",
        "class_weights_dict = {\n",
        "    \"bacterial_spot\": 0.4604,\n",
        "    \"early_blight\": 0.4601,\n",
        "    \"healthy\": 0.4600,\n",
        "    \"late_blight\": 0.4598,\n",
        "    \"leaf_miner\": 0.7170,\n",
        "    \"leaf_mold\": 0.4607,\n",
        "    \"magnesium_deficiency\": 0.7560,\n",
        "    \"mosaic_virus\": 0.4626,\n",
        "    \"nitrogen_deficiency\": 1.5197,\n",
        "    \"potassium_deficiency\": 6.6130,\n",
        "    \"powdery_mildew\": 0.6425,\n",
        "    \"septoria_leaf_spot\": 0.4607,\n",
        "    \"spider_mites\": 0.4647,\n",
        "    \"spotted_wilt_virus\": 1.1381,\n",
        "    \"target_spot\": 0.4648,\n",
        "    \"yellow_leaf_curl_virus\": 0.4600\n",
        "}"
      ],
      "metadata": {
        "id": "z7L7n8KaVDLd"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = torch.tensor(\n",
        "    [class_weights_dict[c] for c in teacher_dataset.classes],\n",
        "    dtype=torch.float\n",
        ").cuda()   # move to GPU"
      ],
      "metadata": {
        "id": "RcTKjZhXVIvz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)"
      ],
      "metadata": {
        "id": "jKgc6NM7Vdlp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WeightedRandomSampler (Data-Level Fix)**"
      ],
      "metadata": {
        "id": "Yfh_de2CVgSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import WeightedRandomSampler"
      ],
      "metadata": {
        "id": "3Mf8Sb1DVeJ5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count samples per class\n",
        "class_counts = [0] * len(teacher_dataset.classes)\n",
        "\n",
        "for _, label in teacher_dataset.samples:\n",
        "    class_counts[label] += 1"
      ],
      "metadata": {
        "id": "-8U3DFLiViZ4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse frequency per class\n",
        "class_sample_weights = [\n",
        "    1.0 / class_counts[label]\n",
        "    for _, label in teacher_dataset.samples\n",
        "]"
      ],
      "metadata": {
        "id": "yxzqvcI_Vjhg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = WeightedRandomSampler(\n",
        "    weights=class_sample_weights,\n",
        "    num_samples=len(class_sample_weights),\n",
        "    replacement=True\n",
        ")"
      ],
      "metadata": {
        "id": "NJnGfh-jVlEZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_loader = DataLoader(\n",
        "    teacher_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=sampler,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "qaMv9CuPVmn_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cap Extreme Oversampling**"
      ],
      "metadata": {
        "id": "AVB7NZ57Vssh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_CLASS_WEIGHT = 5.0\n",
        "\n",
        "class_sample_weights = [\n",
        "    min(1.0 / class_counts[label], MAX_CLASS_WEIGHT)\n",
        "    for _, label in teacher_dataset.samples\n",
        "]"
      ],
      "metadata": {
        "id": "XQKgPpr9Vn-k"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Teacher Model Training**"
      ],
      "metadata": {
        "id": "UCIpYsIvVxYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in teacher_loader:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "xT3zwLsnVrb7",
        "outputId": "6e11cf70-4c9b-4497-ea51-629a193f583e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-622779496.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GzPvbELBV1Be"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}