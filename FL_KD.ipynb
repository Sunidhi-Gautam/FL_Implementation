{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCs4i_erSmMt",
    "outputId": "41d28b8f-8a72-4174-c3b9-49f669902d8c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "0xPQiG1lSxxi",
    "outputId": "668d94cc-6c40-468f-ea2e-9a3f2489b636"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oAQRVA9iSzRV"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZLbt2f7S08L"
   },
   "source": [
    "**Imports for the Dataset Download**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2dhWArxS41w",
    "outputId": "5e3f4daa-a60b-4a59-90c8-d31be5258906"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wac5uYAEM7CA",
    "outputId": "2fe3ef80-6355-4baa-c6d0-de67ed101bb5"
   },
   "outputs": [],
   "source": [
    "RAW_DATASETS_DIR = \"/content/raw_teacher_datasets\"\n",
    "os.makedirs(RAW_DATASETS_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Raw datasets will be stored in:\", RAW_DATASETS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygDDt_uUS7Yc"
   },
   "source": [
    "**Dataset 1: Tomato Village**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u36l3DHRS6rd",
    "outputId": "611f4767-934a-4426-bd8a-30fd1f6cc8e1"
   },
   "outputs": [],
   "source": [
    "print(\"Downloading Dataset 1: Tomato Village (GitHub)\")\n",
    "\n",
    "!git clone https://github.com/mamta-joshi-gehlot/Tomato-Village.git /content/tmp_tomato_village\n",
    "\n",
    "shutil.move(\n",
    "    \"/content/tmp_tomato_village\",\n",
    "    os.path.join(RAW_DATASETS_DIR, \"dataset_1_tomato_village\")\n",
    ")\n",
    "\n",
    "print(\"Dataset 1 ready\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jEE_miuNo61"
   },
   "source": [
    "**Dataset 2: Kaggle 1 (Tomato Leaf)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIV0NGgqNm_3",
    "outputId": "ef8ad46b-1fb7-49b7-fe46-4095f7caea90"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "print(\"Downloading Dataset 2: Tomato Leaf (Kaggle)\")\n",
    "\n",
    "!kaggle datasets download -d kaustubhb999/tomatoleaf -p /content\n",
    "\n",
    "zip_path = \"/content/tomatoleaf.zip\"\n",
    "extract_path = \"/content/tmp_tomatoleaf\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    z.extractall(extract_path)\n",
    "\n",
    "shutil.move(\n",
    "    extract_path,\n",
    "    os.path.join(RAW_DATASETS_DIR, \"dataset_2_tomatoleaf\")\n",
    ")\n",
    "\n",
    "print(\"Dataset 2 ready\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1CQSOgoNwsM"
   },
   "source": [
    "**Dataset 3: Kaggle 2 (Tomato â€“ Ashish Motwani)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zQx-gFrN3Tj",
    "outputId": "07afbd3e-9173-4c90-a708-6c8df3eb32b5"
   },
   "outputs": [],
   "source": [
    "print(\"Downloading Dataset 3: Tomato (Kaggle - Ashish Motwani)\")\n",
    "\n",
    "!kaggle datasets download -d ashishmotwani/tomato -p /content\n",
    "\n",
    "zip_path = \"/content/tomato.zip\"\n",
    "extract_path = \"/content/tmp_tomato_3\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    z.extractall(extract_path)\n",
    "\n",
    "shutil.move(\n",
    "    extract_path,\n",
    "    os.path.join(RAW_DATASETS_DIR, \"dataset_3_tomato\")\n",
    ")\n",
    "\n",
    "print(\"Dataset 3 ready\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB1kwgi1N4j8"
   },
   "source": [
    "**Dataset 4: Kaggle 3 (Tomato Disease)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YstSPA7DNjO8",
    "outputId": "c128d254-8775-48b5-ca18-8968fbd0312e"
   },
   "outputs": [],
   "source": [
    "print(\"Downloading Dataset 4: Tomato Diseases (Kaggle)\")\n",
    "\n",
    "!kaggle datasets download -d luisolazo/tomato-diseases -p /content\n",
    "\n",
    "zip_path = \"/content/tomato-diseases.zip\"\n",
    "extract_path = \"/content/tmp_tomato_diseases\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    z.extractall(extract_path)\n",
    "\n",
    "shutil.move(\n",
    "    extract_path,\n",
    "    os.path.join(RAW_DATASETS_DIR, \"dataset_4_tomato_diseases\")\n",
    ")\n",
    "\n",
    "print(\"Dataset 4 ready\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNWqnNDBOCRG"
   },
   "source": [
    "**Verify Downloads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jd13u60TOBL4",
    "outputId": "96d97a99-9651-4492-b3c0-064cbbd11c8a"
   },
   "outputs": [],
   "source": [
    "print(\"\\nFinal raw datasets available:\\n\")\n",
    "\n",
    "for d in sorted(os.listdir(RAW_DATASETS_DIR)):\n",
    "    print(\"â€¢\", d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pd522KwHOgq8"
   },
   "source": [
    "**Canonical Class Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnjcupZfOYX6"
   },
   "outputs": [],
   "source": [
    "CLASS_MAP = {\n",
    "    # Early blight\n",
    "    \"early_blight\": \"early_blight\",\n",
    "    \"Early_blight\": \"early_blight\",\n",
    "    \"Early Blight\": \"early_blight\",\n",
    "    \"tomato___early_blight\": \"early_blight\",\n",
    "    \"tomato__early blight\": \"early_blight\",\n",
    "    \"EARLY-BLIGHT\": \"early_blight\",\n",
    "\n",
    "\n",
    "    # Late blight\n",
    "    \"late_blight\": \"late_blight\",\n",
    "    \"Late_blight\": \"late_blight\",\n",
    "    \"Late Blight\": \"late_blight\",\n",
    "    \"tomato___late_blight\": \"late_blight\",\n",
    "    \"tomato__late blight\": \"late_blight\",\n",
    "\n",
    "\n",
    "    # Bacterial spot\n",
    "    \"bacterial_spot\": \"bacterial_spot\",\n",
    "    \"Bacterial Spot\": \"bacterial_spot\",\n",
    "    \"Tomato___Bacterial_spot\": \"bacterial_spot\",\n",
    "    \"Tomato_bacterial_spot\": \"bacterial_spot\",\n",
    "\n",
    "\n",
    "    # Leaf mold\n",
    "    \"leaf_mold\": \"leaf_mold\",\n",
    "    \"Leaf Mold\": \"leaf_mold\",\n",
    "    \"Leaf_Mold\": \"leaf_mold\",\n",
    "    \"tomato___Leaf_Mold\": \"leaf_mold\",\n",
    "\n",
    "\n",
    "    # Healthy\n",
    "    \"healthy\": \"healthy\",\n",
    "    \"Healthy\": \"healthy\",\n",
    "    \"Tomato___healthy\": \"healthy\",\n",
    "\n",
    "\n",
    "    # Target spot\n",
    "    \"target_spot\": \"target_spot\",\n",
    "    \"Target Spot\": \"target_spot\",\n",
    "    \"Target_Spot\": \"target_spot\",\n",
    "    \"target_spot___\": \"target_spot\",\n",
    "    \"tomato___Target_Spot\": \"target_spot\",\n",
    "\n",
    "\n",
    "    # Powdery Mildew\n",
    "    \"powdery_mildew\": \"powdery_mildew\",\n",
    "    \"Powdery Mildew\": \"powdery_mildew\",\n",
    "    \"Powdery_mildew\": \"powdery_mildew\",\n",
    "    \"Powdery_Mildew\": \"powdery_mildew\",\n",
    "\n",
    "\n",
    "    # Septoria Leaf Spot\n",
    "    \"septoria_leaf_spot\": \"septoria_leaf_spot\",\n",
    "    \"Septoria Leaf Spot\": \"septoria_leaf_spot\",\n",
    "    \"Septorialeafspot\": \"septoria_leaf_spot\",\n",
    "    \"tomato___Septoria_leaf_spot\": \"septoria_leaf_spot\",\n",
    "\n",
    "\n",
    "    # Mosaic virus\n",
    "    \"mosaic_virus\": \"mosaic_virus\",\n",
    "    \"Tomato_mosaic_virus\": \"mosaic_virus\",\n",
    "    \"tomato_mosaic_virus\": \"mosaic_virus\",\n",
    "    \"Tomato mosaic virus\": \"mosaic_virus\",\n",
    "    \"tomato___Tomato_mosaic_virus\": \"mosaic_virus\",\n",
    "\n",
    "\n",
    "    # Spider mites (Two-spotted)\n",
    "    \"spider_mites_two_spotted_spider_mite\": \"spider_mites\",\n",
    "    \"Spider Mites Two-spotted spider_mite\": \"spider_mites\",\n",
    "    \"Spider_mites\": \"spider_mites\",\n",
    "    \"spider_mites\": \"spider_mites\",\n",
    "    \"twospotted_spider_mite\": \"spider_mites\",\n",
    "    \"Tomato___Spider_mites Two-spotted_spider_mite\": \"spider_mites\",\n",
    "\n",
    "\n",
    "    # Yellow Leaf Curl Virus\n",
    "    \"yellow_leaf_curl_virus\": \"yellow_leaf_curl_virus\",\n",
    "    \"TomatoYellowLeafCurlVirus\": \"yellow_leaf_curl_virus\",\n",
    "    \"Tomato_Yellow_Leaf_Curl_Virus\": \"yellow_leaf_curl_virus\",\n",
    "    \"Yellow Leaf Curl Virus\": \"yellow_leaf_curl_virus\",\n",
    "    \"tomato___Tomato_Yellow_Leaf_Curl_Virus\": \"yellow_leaf_curl_virus\",\n",
    "\n",
    "\n",
    "    # Leaf Miner\n",
    "    \"leaf_miner\": \"leaf_miner\",\n",
    "    \"Leaf Miner\": \"leaf_miner\",\n",
    "    \"leaf miner\": \"leaf_miner\",\n",
    "\n",
    "\n",
    "    # Nitrogen deficiency\n",
    "    \"nitrogen_deficiency\": \"nitrogen_deficiency\",\n",
    "    \"Nitrogen Deficiency\": \"nitrogen_deficiency\",\n",
    "\n",
    "\n",
    "    # Potassium deficiency\n",
    "    \"potassium_deficiency\": \"potassium_deficiency\",\n",
    "    \"Pottassium Deficiency\": \"potassium_deficiency\",\n",
    "    \"Potassium Deficiency\": \"potassium_deficiency\",\n",
    "\n",
    "\n",
    "    # Magnesium deficiency\n",
    "    \"magnesium_deficiency\": \"magnesium_deficiency\",\n",
    "    \"Magnesium Deficiency\": \"magnesium_deficiency\",\n",
    "\n",
    "\n",
    "    # Spotted Wilt Virus\n",
    "    \"spotted_wilt_virus\": \"spotted_wilt_virus\",\n",
    "    \"Spotted Wilt Virus\": \"spotted_wilt_virus\",\n",
    "    \"Spotted_Wilt_Virus\": \"spotted_wilt_virus\",\n",
    "    \"Spotted wilt virus\": \"spotted_wilt_virus\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_QuXcMtOlgo"
   },
   "outputs": [],
   "source": [
    "RAW_DATASETS_DIR = \"/content/raw_teacher_datasets\"\n",
    "TEACHER_DATASET_DIR = \"/content/teacher_dataset\"\n",
    "\n",
    "os.makedirs(TEACHER_DATASET_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHm4SR4WSF5c"
   },
   "outputs": [],
   "source": [
    "IGNORE_FOLDERS = {\n",
    "    \"train\", \"val\", \"test\",\n",
    "    \"images\", \"image\", \"imgs\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVbcQ9x3On8Z"
   },
   "source": [
    "**Normalize Class Names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoBKiWIDOnRE"
   },
   "outputs": [],
   "source": [
    "def normalize_class_name(raw):\n",
    "    raw = raw.strip().lower()\n",
    "\n",
    "    # Ignore structural folders\n",
    "    if raw in IGNORE_FOLDERS:\n",
    "        return None\n",
    "\n",
    "    # Remove PlantVillage prefix\n",
    "    if raw.startswith(\"tomato___\"):\n",
    "        raw = raw.replace(\"tomato___\", \"\")\n",
    "\n",
    "    # Cleanup\n",
    "    raw = raw.replace(\"-\", \"_\")\n",
    "    raw = raw.replace(\" \", \"_\")\n",
    "    raw = raw.replace(\"__\", \"_\")\n",
    "\n",
    "    # ---- Canonical merges ----\n",
    "\n",
    "    if \"spider\" in raw or \"mite\" in raw:\n",
    "        return \"spider_mites\"\n",
    "\n",
    "    if \"yellow\" in raw and \"curl\" in raw:\n",
    "        return \"yellow_leaf_curl_virus\"\n",
    "\n",
    "    if \"mosaic\" in raw:\n",
    "        return \"mosaic_virus\"\n",
    "\n",
    "    if \"septoria\" in raw:\n",
    "        return \"septoria_leaf_spot\"\n",
    "\n",
    "    if \"early\" in raw and \"blight\" in raw:\n",
    "        return \"early_blight\"\n",
    "\n",
    "    if \"late\" in raw and \"blight\" in raw:\n",
    "        return \"late_blight\"\n",
    "\n",
    "    if \"target\" in raw:\n",
    "        return \"target_spot\"\n",
    "\n",
    "    if \"leaf\" in raw and \"mold\" in raw:\n",
    "        return \"leaf_mold\"\n",
    "\n",
    "    # Nutrient deficiencies\n",
    "    if \"nitrogen\" in raw:\n",
    "        return \"nitrogen_deficiency\"\n",
    "\n",
    "    if \"pottassium\" in raw or \"potassium\" in raw:\n",
    "        return \"potassium_deficiency\"\n",
    "\n",
    "    if \"magnesium\" in raw:\n",
    "        return \"magnesium_deficiency\"\n",
    "\n",
    "    # Healthy\n",
    "    if raw == \"healthy\":\n",
    "        return \"healthy\"\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HO04qK7gSNS4"
   },
   "outputs": [],
   "source": [
    "TEACHER_DATASET_DIR = \"/content/teacher_dataset\"\n",
    "\n",
    "if os.path.exists(TEACHER_DATASET_DIR):\n",
    "    shutil.rmtree(TEACHER_DATASET_DIR)\n",
    "\n",
    "os.makedirs(TEACHER_DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9_arqxpOw0c"
   },
   "source": [
    "**Merge & Normalizing All Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4k6O4wUOvOW",
    "outputId": "6a0c4bd3-a5b9-4660-cea8-b766efe15942"
   },
   "outputs": [],
   "source": [
    "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "class_counter = {}\n",
    "total_images = 0\n",
    "\n",
    "for dataset in sorted(os.listdir(RAW_DATASETS_DIR)):\n",
    "    dataset_path = os.path.join(RAW_DATASETS_DIR, dataset)\n",
    "    print(f\"\\nProcessing {dataset}\")\n",
    "\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        imgs = [f for f in files if f.lower().endswith(IMG_EXTS)]\n",
    "        if not imgs:\n",
    "            continue\n",
    "\n",
    "        raw_class = os.path.basename(root)\n",
    "        norm_class = normalize_class_name(raw_class)\n",
    "\n",
    "        if norm_class is None:\n",
    "            continue\n",
    "\n",
    "        dest_cls_dir = os.path.join(TEACHER_DATASET_DIR, norm_class)\n",
    "        os.makedirs(dest_cls_dir, exist_ok=True)\n",
    "\n",
    "        for img in imgs:\n",
    "            src = os.path.join(root, img)\n",
    "            dst = os.path.join(dest_cls_dir, f\"{dataset}_{img}\")\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "            class_counter[norm_class] = class_counter.get(norm_class, 0) + 1\n",
    "            total_images += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlnmWab-O3Oa"
   },
   "source": [
    "**Teacher Dataset Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwUlVD1jO2fC",
    "outputId": "73e09f70-b9cb-469f-fabd-b4225c695616"
   },
   "outputs": [],
   "source": [
    "print(\"\\n===== CLEAN TEACHER DATASET SUMMARY =====\")\n",
    "print(f\"Total images: {total_images}\")\n",
    "print(f\"Total classes: {len(class_counter)}\\n\")\n",
    "\n",
    "for cls, cnt in sorted(class_counter.items()):\n",
    "    print(f\"{cls:<30} {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPHZOPBfXhp1"
   },
   "source": [
    "**Teacher Dataset Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovIsAv_8XeKh"
   },
   "outputs": [],
   "source": [
    "RAW_TEACHER = \"/content/teacher_dataset\"\n",
    "SPLIT_DIR = \"/content/teacher_dataset_split\"\n",
    "\n",
    "TRAIN_DIR = os.path.join(SPLIT_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(SPLIT_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(SPLIT_DIR, \"test\")\n",
    "\n",
    "for d in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "    if os.path.exists(d):\n",
    "        shutil.rmtree(d)\n",
    "    os.makedirs(d)\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio   = 0.15\n",
    "test_ratio  = 0.15\n",
    "\n",
    "random.seed(42)\n",
    "classes = sorted(os.listdir(RAW_TEACHER))\n",
    "\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(RAW_TEACHER, cls)\n",
    "    if not os.path.isdir(cls_path):\n",
    "        continue\n",
    "    images = os.listdir(cls_path)\n",
    "    random.shuffle(images)\n",
    "\n",
    "    n = len(images)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val   = int(n * val_ratio)\n",
    "    n_test  = n - n_train - n_val\n",
    "\n",
    "    train_imgs = images[:n_train]\n",
    "    val_imgs   = images[n_train:n_train+n_val]\n",
    "    test_imgs  = images[n_train+n_val:]\n",
    "\n",
    "    for folder, imgs in zip([TRAIN_DIR, VAL_DIR, TEST_DIR], [train_imgs, val_imgs, test_imgs]):\n",
    "        cls_folder = os.path.join(folder, cls)\n",
    "        os.makedirs(cls_folder, exist_ok=True)\n",
    "        for img in imgs:\n",
    "            shutil.copy(os.path.join(cls_path, img), os.path.join(cls_folder, img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdV5hAwuXqwT"
   },
   "source": [
    "**Data Transforms & DataLoaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cmw0TSrVXxPY"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transform)\n",
    "test_dataset = datasets.ImageFolder(TEST_DIR, transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSFCSODhTNht"
   },
   "source": [
    "**Handling Class Imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XgPj8UMTT3u"
   },
   "source": [
    "**Class Frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ww4WTR7qRubq",
    "outputId": "7292e9db-6be0-4c22-bfdf-339724c84cea"
   },
   "outputs": [],
   "source": [
    "# Path to train folder\n",
    "train_dir = os.path.join(SPLIT_DIR, \"train\")\n",
    "\n",
    "# Count samples per class in training set\n",
    "class_counts = Counter()\n",
    "for cls in os.listdir(train_dir):\n",
    "    cls_path = os.path.join(train_dir, cls)\n",
    "    if not os.path.isdir(cls_path):\n",
    "        continue\n",
    "    class_counts[cls] = len(os.listdir(cls_path))\n",
    "\n",
    "print(\"===== CLASS FREQUENCIES (Train Set) =====\")\n",
    "for c, n in sorted(class_counts.items()):\n",
    "    print(f\"{c:<30} {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pDnG0jbTbvr"
   },
   "source": [
    "**Computing Class-Balanced Weights (CB-Loss)**\n",
    "\n",
    "$$\n",
    "w_c = \\frac{1 - \\beta}{1 - \\beta^{n_c}}\n",
    "$$\n",
    "\n",
    "n_c = no. of samples in class c\n",
    "\n",
    "Î² Ïµ [0.9, 0.9999]\n",
    "\n",
    "Larger Î² --> stronger balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhWiPPjHZkhc"
   },
   "outputs": [],
   "source": [
    "class_counts = [0]*len(train_dataset.classes)\n",
    "for _, label in train_dataset.samples:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "beta = 0.999\n",
    "effective_num = [1 - beta**n for n in class_counts]\n",
    "weights = [(1-beta)/n for n in effective_num]\n",
    "weights = np.array(weights)\n",
    "weights = weights / weights.sum() * len(weights)\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnuhZ_KtaHpa"
   },
   "source": [
    "**WeightedRandomSampler***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJ2yfVLsaG28"
   },
   "outputs": [],
   "source": [
    "MAX_CLASS_WEIGHT = 5.0\n",
    "sample_weights = [min(1.0 / class_counts[label], MAX_CLASS_WEIGHT) for _, label in train_dataset.samples]\n",
    "\n",
    "train_sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                      num_samples=len(sample_weights),\n",
    "                                      replacement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtwV9lVUaOF5"
   },
   "source": [
    "**DataLoaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKcyXVObaM44"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stHBB0keU7GU"
   },
   "source": [
    "**Loading Teacher Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "1326e1da21574fd4abeaa6b30c83ed95",
      "6a13cd60baf84d8393f6e44ac8145820",
      "8f0666719a6b49bc9fbf8b60c1c52d56",
      "2a737b7967fc4a1cbd45f875a5da6827",
      "67d14858a6f9406fa13db079fe22d2fd",
      "efa0db51b9cb43979e17c36e6230b28f",
      "2764b0d31b7143e082decfe07955ef36",
      "c70b929ade4948cabe739850f02ef47f",
      "9093c6c647f746eda9af970c541967f9",
      "667a30d932a74737968e1d2fffef70c2",
      "90374e1a3d25452ba79f1bc14530c8cd"
     ]
    },
    "id": "AfGi8nrFX5gq",
    "outputId": "5c9fc807-cbfa-4921-cff3-965a4ad1c9c8"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "teacher_model = timm.create_model('efficientnet_b2', pretrained=True, num_classes=len(train_dataset.classes))\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(teacher_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mzuwn_o-X1fA"
   },
   "source": [
    "**Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArAWQbHBUrGj",
    "outputId": "3633bad4-1b35-4fb6-e637-37d72a48399b"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    # --- Training ---\n",
    "    teacher_model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for images, labels in train_loader_tqdm:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = teacher_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Update live progress bar with current batch accuracy & loss\n",
    "        train_loader_tqdm.set_postfix({\n",
    "            \"Loss\": f\"{running_loss/total:.4f}\",\n",
    "            \"Acc\": f\"{correct/total:.4f}\"\n",
    "        })\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # --- Validation ---\n",
    "    teacher_model.eval()\n",
    "    val_running_loss, val_correct, val_total = 0, 0, 0\n",
    "\n",
    "    val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "    for images, labels in val_loader_tqdm:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = teacher_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        val_running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        val_correct += (preds == labels).sum().item()\n",
    "        val_total += labels.size(0)\n",
    "\n",
    "        val_loader_tqdm.set_postfix({\n",
    "            \"Loss\": f\"{val_running_loss/val_total:.4f}\",\n",
    "            \"Acc\": f\"{val_correct/val_total:.4f}\"\n",
    "        })\n",
    "\n",
    "    val_loss = val_running_loss / val_total\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    # --- Save history ---\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    # --- Epoch summary ---\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Save history\n",
    "torch.save(history, \"teacher_history.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAyXT0pdc5L6"
   },
   "outputs": [],
   "source": [
    "torch.save(teacher_model.state_dict(), \"teacher_efficientnet_b2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "cNFgEFSCtA_F",
    "outputId": "c855e3c6-b219-4377-a9d8-fc9d75bdd7e4"
   },
   "outputs": [],
   "source": [
    "# --- Plot training & validation curves ---\n",
    "history = torch.load(\"teacher_history.pt\")  # Load your saved history\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, history['train_loss'], label='Train Loss', marker='o')\n",
    "plt.plot(epochs, history['val_loss'], label='Val Loss', marker='o')\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, history['train_acc'], label='Train Acc', marker='o')\n",
    "plt.plot(epochs, history['val_acc'], label='Val Acc', marker='o')\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J3BVQNaZtE5z",
    "outputId": "75530a51-9104-43b2-8ea4-d13ec0e7d8a8"
   },
   "outputs": [],
   "source": [
    "# --- Evaluate on test set ---\n",
    "teacher_model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = teacher_model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "test_acc = test_correct / test_total\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWbfguRltLl4",
    "outputId": "9e5293db-5aed-4299-bdcd-cb21bf56e749"
   },
   "outputs": [],
   "source": [
    "teacher_model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = teacher_model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"\\n===== CLASSIFICATION REPORT (TEST SET) =====\\n\")\n",
    "print(\n",
    "    classification_report(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        target_names=test_dataset.classes,\n",
    "        digits=4\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-RcgYiCt0na"
   },
   "outputs": [],
   "source": [
    "with open(\"teacher_classes.json\", \"w\") as f:\n",
    "    json.dump(train_dataset.classes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pqvwnmWATul",
    "outputId": "f667c603-49c0-4a68-d41f-04fa0f1086fa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Io2R0wbQAXLT"
   },
   "outputs": [],
   "source": [
    "import os, json, torch\n",
    "\n",
    "SAVE_DIR = \"/content/drive/MyDrive/teacher_model\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# save model\n",
    "torch.save(\n",
    "    teacher_model.state_dict(),\n",
    "    f\"{SAVE_DIR}/teacher_efficientnet_b2.pth\"\n",
    ")\n",
    "\n",
    "# save classes\n",
    "with open(f\"{SAVE_DIR}/teacher_classes.json\", \"w\") as f:\n",
    "    json.dump(train_dataset.classes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBhaXJeqAsWK"
   },
   "outputs": [],
   "source": [
    "experiment_info = {\n",
    "    \"dataset\": \"tomato-leaf-disease\",\n",
    "    \"source\": \"Kaggle\",\n",
    "    \"num_classes\": len(train_dataset.classes),\n",
    "    \"classes\": train_dataset.classes,\n",
    "    \"input_size\": 260,\n",
    "    \"model\": \"efficientnet_b2\",\n",
    "    \"epochs\": 10,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"best_val_acc\": 0.9832\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"/content/drive/MyDrive/teacher_model/experiment.json\", \"w\") as f:\n",
    "    json.dump(experiment_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdjeWbaWAWwL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "WtDrUy9Ftcew",
    "outputId": "a9be4161-60d1-40a7-e047-8af0f30fcda0"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()   # upload .pth and .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hormDz9huFIb",
    "outputId": "b7c82913-6387-4308-f037-5876ce18014c"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open(\"teacher_classes.json\") as f:\n",
    "    classes = json.load(f)\n",
    "\n",
    "teacher_model = timm.create_model(\n",
    "    'efficientnet_b2',\n",
    "    pretrained=False,        # IMPORTANT\n",
    "    num_classes=len(classes)\n",
    ")\n",
    "\n",
    "teacher_model.load_state_dict(\n",
    "    torch.load(\"teacher_efficientnet_b2.pth\", map_location=device)\n",
    ")\n",
    "\n",
    "teacher_model = teacher_model.to(device)\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WvV8PQPuEvG"
   },
   "source": [
    "**Saving the Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7IuIABGDgu9"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/drive/MyDrive/teacher_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-hFuyjauVun"
   },
   "outputs": [],
   "source": [
    "!mkdir -p /content/drive/MyDrive/teacher_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S55bjFXZDmWT"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/teacher_dataset/* /content/drive/MyDrive/teacher_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HKwgGvBnDgQg"
   },
   "outputs": [],
   "source": [
    "SRC_SPLIT_DIR = \"/content/teacher_dataset_split\"\n",
    "DRIVE_SPLIT_DIR = \"/content/drive/MyDrive/teacher_dataset_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3ZtO8PIuZl2",
    "outputId": "65c277ac-bd3e-4ffc-c0a4-48539f98a389"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if os.path.exists(DRIVE_SPLIT_DIR):\n",
    "    shutil.rmtree(DRIVE_SPLIT_DIR)\n",
    "\n",
    "os.makedirs(DRIVE_SPLIT_DIR)\n",
    "print(\"ðŸ§¹ Old broken split removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvSsIhcAEEmi",
    "outputId": "db4fb04e-78e0-4a44-9743-f215fba6233c"
   },
   "outputs": [],
   "source": [
    "shutil.copytree(SRC_SPLIT_DIR, DRIVE_SPLIT_DIR, dirs_exist_ok=True)\n",
    "print(\"âœ… Teacher split dataset saved to Drive correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7moiH3PueKg"
   },
   "outputs": [],
   "source": [
    "!cp teacher_history.pt /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MkM3FwpJl8J",
    "outputId": "b5eb6fdb-55b5-4709-dcc2-35d1840c0ccb"
   },
   "outputs": [],
   "source": [
    "!ls /content/drive/MyDrive/teacher_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bK3ZdT0WJocy",
    "outputId": "8d6059bd-a93b-497f-cec2-70cee8c549c1"
   },
   "outputs": [],
   "source": [
    "!find /content/drive/MyDrive/teacher_dataset -maxdepth 1 -type d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzY-Wx7MJrmX",
    "outputId": "c7815664-86ce-4f34-c13c-e799a663e2be"
   },
   "outputs": [],
   "source": [
    "!ls /content/drive/MyDrive/teacher_dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTwOdkHvJyvm",
    "outputId": "2635d23c-1431-441c-c7bb-c452dbaf9d2f"
   },
   "outputs": [],
   "source": [
    "!find /content/drive/MyDrive/teacher_dataset_split/ -maxdepth 2 -type d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb8-N4AhvG5W"
   },
   "source": [
    "**Reloading From Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNx4Sy6MvK7R",
    "outputId": "0a3d427e-e5ea-4ad9-ac3d-4e0f87b4cc0a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0EN497-LvPwK"
   },
   "outputs": [],
   "source": [
    "TEACHER_DATASET_DIR = \"/content/drive/MyDrive/teacher_dataset\"\n",
    "SPLIT_DIR = \"/content/drive/MyDrive/teacher_dataset_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o8FAFCscvTNF",
    "outputId": "e118d402-8b22-4391-f35f-f4a004025adb"
   },
   "outputs": [],
   "source": [
    "teacher_model.load_state_dict(\n",
    "    torch.load(\"/content/drive/MyDrive/teacher_efficientnet_b2.pth\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsEt2fVBw2Go",
    "outputId": "0b198d1b-3626-4818-db85-16f96ed9f727"
   },
   "outputs": [],
   "source": [
    "teacher_model = teacher_model.to(device)\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BD8ue_ElKOba"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "teacher_model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = teacher_model(images)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NcnhfSXKvmK",
    "outputId": "08883b3b-f4aa-4889-acd4-5586bb3d6fd4"
   },
   "outputs": [],
   "source": [
    "class_names = test_dataset.classes   # safest\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3RTORnUKyzn"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "rqXSKsvTK2HV",
    "outputId": "d72d9e4a-6581-4da0-894d-40d2a3312fb9"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix â€“ Teacher Model (Test Set)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ES_00iEcK70U",
    "outputId": "4be07f40-a6fd-455b-cd56-a6278f1f0892"
   },
   "outputs": [],
   "source": [
    "cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(\n",
    "    cm_norm,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"Greens\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Normalized Confusion Matrix â€“ Teacher Model (Test Set)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMuO7ZTCLUw1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
